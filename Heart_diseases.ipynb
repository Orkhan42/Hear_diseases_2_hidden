{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"heart_disease_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlar=df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=adlar[0].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age;sex;chest_pain_type;resting_blood_pressure;cholesterol;fasting_blood_sugar;rest_ecg;max_heart_rate_achieved;exercise_induced_angina;st_depression;st_slope;num_major_vessels;thalassemia;target'], dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['age;sex;chest_pain_type;resting_blood_pressure;cholesterol;fasting_blood_sugar;rest_ecg;max_heart_rate_achieved;exercise_induced_angina;st_depression;st_slope;num_major_vessels;thalassemia;target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "listem=list()\n",
    "for i in range(303):\n",
    "    listem.append(x[i].split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(303):\n",
    "    for j in range(14):\n",
    "        listem[i][j]=float(listem[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(listem,columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>rest_ecg</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>st_slope</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>thalassemia</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex  chest_pain_type  resting_blood_pressure  cholesterol  \\\n",
       "0  63.0  1.0              3.0                   145.0        233.0   \n",
       "1  37.0  1.0              2.0                   130.0        250.0   \n",
       "2  41.0  0.0              1.0                   130.0        204.0   \n",
       "3  56.0  1.0              1.0                   120.0        236.0   \n",
       "4  57.0  0.0              0.0                   120.0        354.0   \n",
       "\n",
       "   fasting_blood_sugar  rest_ecg  max_heart_rate_achieved  \\\n",
       "0                  1.0       0.0                    150.0   \n",
       "1                  0.0       1.0                    187.0   \n",
       "2                  0.0       0.0                    172.0   \n",
       "3                  0.0       1.0                    178.0   \n",
       "4                  0.0       1.0                    163.0   \n",
       "\n",
       "   exercise_induced_angina  st_depression  st_slope  num_major_vessels  \\\n",
       "0                      0.0            2.3       0.0                0.0   \n",
       "1                      0.0            3.5       0.0                0.0   \n",
       "2                      0.0            1.4       2.0                0.0   \n",
       "3                      0.0            0.8       2.0                0.0   \n",
       "4                      1.0            0.6       2.0                0.0   \n",
       "\n",
       "   thalassemia  target  \n",
       "0          1.0     1.0  \n",
       "1          2.0     1.0  \n",
       "2          2.0     1.0  \n",
       "3          2.0     1.0  \n",
       "4          2.0     1.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      303 non-null    float64\n",
      " 1   sex                      303 non-null    float64\n",
      " 2   chest_pain_type          303 non-null    float64\n",
      " 3   resting_blood_pressure   303 non-null    float64\n",
      " 4   cholesterol              303 non-null    float64\n",
      " 5   fasting_blood_sugar      303 non-null    float64\n",
      " 6   rest_ecg                 303 non-null    float64\n",
      " 7   max_heart_rate_achieved  303 non-null    float64\n",
      " 8   exercise_induced_angina  303 non-null    float64\n",
      " 9   st_depression            303 non-null    float64\n",
      " 10  st_slope                 303 non-null    float64\n",
      " 11  num_major_vessels        303 non-null    float64\n",
      " 12  thalassemia              303 non-null    float64\n",
      " 13  target                   303 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'chest_pain_type', 'resting_blood_pressure',\n",
       "       'cholesterol', 'fasting_blood_sugar', 'rest_ecg',\n",
       "       'max_heart_rate_achieved', 'exercise_induced_angina', 'st_depression',\n",
       "       'st_slope', 'num_major_vessels', 'thalassemia', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:, :-1]\n",
    "y=df.iloc[:,  -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.ci sualıda bezi sözlü suallar soruşulub. input (303,14),output ise (303,1) olacaq. parametrler ise her layerde olan \n",
    "# weight'ler olacaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def mse_loss_derivative(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return (2*(y_true - y_pred))\n",
    "\n",
    "class ArtificialNeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.IN      = x\n",
    "        self.W1   = np.random.rand(self.IN.shape[1],4) \n",
    "        self.W2   = np.random.rand(4,1)                 \n",
    "        self.y          = y\n",
    "        self.OUT     = np.zeros(self.y.shape)\n",
    "        self.learning_rate = 0.3\n",
    "\n",
    "    def feed_forward(self):\n",
    "        self.HIDDEN_LAYER_1 = sigmoid(np.dot(self.IN, self.W1))\n",
    "        self.output = sigmoid(np.dot(self.HIDDEN_LAYER_1, self.W2))\n",
    "\n",
    "    def back_propagate(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to W2 and W1\n",
    "        print(self.HIDDEN_LAYER_1.T)\n",
    "        d_W2 = np.dot(self.HIDDEN_LAYER_1.T, (mse_loss_derivative(self.y, self.output) * sigmoid_derivative(self.output)))\n",
    "        print(d_W2)\n",
    "        d_W1 = np.dot(self.IN.T,  (np.dot(mse_loss_derivative(self.y, self.output) * sigmoid_derivative(self.output), self.W2.T) * sigmoid_derivative(self.HIDDEN_LAYER_1)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.W1 += self.learning_rate*d_W1\n",
    "        self.W2 += self.learning_rate*d_W2\n",
    "\n",
    "    def train(self, epochs,learning_rate):\n",
    "        self.learning_rate=learning_rate\n",
    "        for i in range(epochs):\n",
    "            self.feed_forward()\n",
    "            self.back_propagate()\n",
    "        print(\"Successfully Trained the Model\")\n",
    "        print(\"Weights 1:\", self.W1)\n",
    "        print(\"Weights 2:\", self.W2)\n",
    "    \n",
    "    def print_output(self):\n",
    "        print(self.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]]\n",
      "[[  7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788]\n",
      " [  7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788]\n",
      " [  7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788]\n",
      " [  7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788 -47.40955788 -47.40955788 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788 -47.40955788   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976 -47.40955788 -47.40955788   7.03203976 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "  -47.40955788   7.03203976   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788   7.03203976   7.03203976 -47.40955788\n",
      "    7.03203976 -47.40955788   7.03203976 -47.40955788 -47.40955788\n",
      "    7.03203976   7.03203976   7.03203976 -47.40955788   7.03203976\n",
      "    7.03203976   7.03203976 -47.40955788   7.03203976 -47.40955788\n",
      "  -47.40955788 -47.40955788   7.03203976 -47.40955788   7.03203976\n",
      "  -47.40955788   7.03203976 -47.40955788   7.03203976   7.03203976\n",
      "  -47.40955788 -47.40955788]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (242,242) and (1,4) not aligned: 242 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-a7c0d175be02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArtificialNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-170-689ac8b50936>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully Trained the Model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Weights 1:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-689ac8b50936>\u001b[0m in \u001b[0;36mback_propagate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0md_W2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIDDEN_LAYER_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmse_loss_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_W2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0md_W1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse_loss_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msigmoid_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIDDEN_LAYER_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# update the weights with the derivative (slope) of the loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (242,242) and (1,4) not aligned: 242 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "X=x_train.to_numpy()\n",
    "y=y_train.to_numpy()\n",
    "epochs = 2\n",
    "learning_rate = 0.5\n",
    "ann = ArtificialNeuralNetwork(X,y)\n",
    "ann.train(epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
